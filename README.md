IMDB Film YorumlarÄ± ile Duygu Analizi
Bu proje, IMDB film yorumlarÄ± veri setini kullanarak metin sÄ±nÄ±flandÄ±rma ve duygu analizi gerÃ§ekleÅŸtirir. Projenin amacÄ±, bir film yorumunun "pozitif" mi yoksa "negatif" mi olduÄŸunu makine Ã¶ÄŸrenmesi modelleriyle tahmin etmektir. Proje, veri temizleme, Ã¶zellik Ã§Ä±karma (feature extraction) ve model karÅŸÄ±laÅŸtÄ±rmasÄ± gibi temel DoÄŸal Dil Ä°ÅŸleme (NLP) adÄ±mlarÄ±nÄ± iÃ§ermektedir.

ğŸš€ Proje AkÄ±ÅŸÄ±
Proje, aÅŸaÄŸÄ±daki adÄ±mlarÄ± takip ederek geliÅŸtirilmiÅŸtir:

Veri YÃ¼kleme ve HazÄ±rlÄ±k: 50.000 film yorumundan oluÅŸan IMDB veri setinin yÃ¼klenmesi ve temel analizinin yapÄ±lmasÄ±.

Metin Temizleme: Yorumlardaki HTML etiketleri, noktalama iÅŸaretleri, sayÄ±lar ve fazla boÅŸluklar gibi gÃ¼rÃ¼ltÃ¼lerin temizlenmesi.

Tokenizasyon ve Lemmatizasyon: TemizlenmiÅŸ metinlerin kelimelere (token) ayrÄ±lmasÄ±, etkisiz kelimelerin (stopwords) Ã§Ä±karÄ±lmasÄ± ve kelimelerin kÃ¶klerine (lemma) indirgenmesi.

VektÃ¶rizasyon: Metin verilerinin makine Ã¶ÄŸrenmesi modellerinin anlayabileceÄŸi sayÄ±sal formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi. Bu aÅŸamada iki farklÄ± yÃ¶ntem kullanÄ±lmÄ±ÅŸtÄ±r:

Bag of Words (BoW)

TF-IDF (Term Frequency-Inverse Document Frequency)

Model EÄŸitimi ve DeÄŸerlendirme: Veri setinin eÄŸitim ve test olarak ikiye ayrÄ±lmasÄ± ve farklÄ± sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ±n her iki vektÃ¶rizasyon tekniÄŸiyle eÄŸitilmesi.

Ã‡apraz DoÄŸrulama ve Hiperparametre Optimizasyonu: Modellerin performansÄ±nÄ± daha gÃ¼venilir bir ÅŸekilde Ã¶lÃ§mek iÃ§in 10 katlÄ± Ã§apraz doÄŸrulama (cross-validation) ve en iyi model parametrelerini bulmak iÃ§in GridSearchCV kullanÄ±lmÄ±ÅŸtÄ±r.

ğŸ”‘ Temel Kavramlar
Bu projede kullanÄ±lan temel DoÄŸal Dil Ä°ÅŸleme (NLP) kavramlarÄ±:

Tokenizasyon (TokenleÅŸtirme): Bir metnin cÃ¼mle, kelime veya alt kelime gibi daha kÃ¼Ã§Ã¼k birimlere (token) ayrÄ±lmasÄ± iÅŸlemidir.

Lemmatizasyon (KÃ¶k Bulma): Bir kelimenin eklerini atarak anlamsal kÃ¶kÃ¼nÃ¼ bulma iÅŸlemidir. Ã–rneÄŸin, "gÃ¶zlÃ¼kÃ§Ã¼" kelimesinin kÃ¶kÃ¼ "gÃ¶z"dÃ¼r. Bu iÅŸlem, kelime daÄŸarcÄ±ÄŸÄ±nÄ± kÃ¼Ã§Ã¼lterek modelin daha verimli Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar.

Stemming (GÃ¶vdeleme): Lemmatizasyona benzer ÅŸekilde kelimelerin eklerini atarak gÃ¶vdesini bulur, ancak bulunan gÃ¶vdenin her zaman sÃ¶zlÃ¼kte anlamlÄ± bir kelime olmasÄ± gerekmez.

Bag of Words (Kelime TorbasÄ±): Bir metni, iÃ§indeki kelimelerin sÄ±rasÄ±nÄ± dikkate almadan, sadece hangi kelimeden kaÃ§ tane geÃ§tiÄŸini sayarak sayÄ±sal bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼ren yÃ¶ntemdir.

TF-IDF (Term Frequency-Inverse Document Frequency): Bir kelimenin bir belge iÃ§indeki Ã¶nemini, o kelimenin belge iÃ§indeki sÄ±klÄ±ÄŸÄ± (TF) ve tÃ¼m belgelerdeki genel sÄ±klÄ±ÄŸÄ±nÄ±n tersi (IDF) ile orantÄ±lÄ± olarak hesaplayan bir istatistiksel yÃ¶ntemdir. Nadir ve Ã¶nemli kelimelere daha yÃ¼ksek aÄŸÄ±rlÄ±k verir.

ğŸ“Š Model PerformansÄ±
Projede KNN, Naive Bayes, Karar AÄŸacÄ±, Lojistik Regresyon ve Random Forest gibi farklÄ± sÄ±nÄ±flandÄ±rma modelleri test edilmiÅŸtir. YapÄ±lan Ã§apraz doÄŸrulama ve hiperparametre optimizasyonu sonucunda en yÃ¼ksek performansÄ± gÃ¶steren modeller ve metrikleri aÅŸaÄŸÄ±daki gibidir:

Model	VektÃ¶rizasyon	F1-Skoru (AÄŸÄ±rlÄ±klÄ±)	DoÄŸruluk
Lojistik Regresyon	TF-IDF	0.8812	0.8812
Naive Bayes	TF-IDF	0.8543	0.8544
Random Forest	TF-IDF	0.8427	0.8427
Karar AÄŸacÄ±	TF-IDF	0.7323	0.7334
Naive Bayes	BoW	0.5100	-
Lojistik Regresyon	BoW	0.5043	-
KNN	TF-IDF	0.5550	0.5627

E-Tablolar'a aktar
ğŸ† En Ä°yi Model
YapÄ±lan deÄŸerlendirmeler sonucunda TF-IDF vektÃ¶rleÅŸtirme tekniÄŸi ile eÄŸitilen Lojistik Regresyon modeli, %88.12 F1-Skoru ile en baÅŸarÄ±lÄ± model olarak belirlenmiÅŸtir. Bu sonuÃ§, kelimelerin belge iÃ§indeki Ã¶nemini dikkate alan TF-IDF yÃ¶nteminin, sadece kelime frekanslarÄ±na dayanan Bag of Words yÃ¶ntemine gÃ¶re bu veri setinde Ã§ok daha Ã¼stÃ¼n olduÄŸunu gÃ¶stermektedir.
